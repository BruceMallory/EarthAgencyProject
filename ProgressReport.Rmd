---
title: "Earth Agency Project: Progress Report"
author: "Consulting Team A, group 3"
date: "March 7th, 2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("knitr","tidyverse","glmnet","car","tidyverse","ggplot2","arm","rstanarm", "magrittr", "brant", "regclass", "plyr", "gplots")
```
   
## 1. Decisions made in creating the working data frame
  
  (a) We have combined *EarthAgency_Adults_R.csv* and *EarthAgency_Children_R.csv* into one data.frame: `AC_df`.  We have done this so that we can make an Adult vs. children comparison.  To combined the two data sets we have done b-d.
  
  (b) To normalize the adult and children's `invitalscores`, we have compressed the adult's scores (which ranged from 0-5), to match the children's scores (which ranged from 0-3).  
``` {r echo=FALSE, message=FALSE, warning=FALSE}
b <- data.frame(original=as.character(seq(0, 5)), normalized=as.character(c(0,0,1,2,3,3)))
kable(t(b))  
```
  
  (c) To normalize the adult and children's `inpsychscore`, we have compressed the adult's scores (which ranged from 0-5), to match the children's scores (which ranged from 0-4).  
``` {r echo=FALSE, message=FALSE, warning=FALSE}
c <- data.frame(original=as.character(seq(0, 5)), normalized=as.character(c(0,1,2,2,3,3)))
kable(t(c))  
```
  
 (d) We have added `FirstLang` to the children's records, and assigned every child a value of 1 for `FirstLang`.  We're assuming that 1=using first language, and 0=not using first language.    
  
 (e) The 87th entry in the children's record's has a `MeanSeverity` of 2.67.  But 2.67 is not a possible value (given that `MeanSeverity` is an average of 4 integer scores, and should thus be a multiple of 0.25).  We've changed the `MeanSeverity` for that record to 2.5.  
  
 (f) The 41st children's record has no `BIoJtscore` or `AntJtscore`.  We did not use this record in the data.frame.  
  
 (g) The 45th children's record has no `Agency_Language` or `SRFactsTotal`.  We did not use this record in the data.frame.
 
 (h) We have not included the independent variable `SRTotal` in the data frame.  Our understanding is that this variable is measuring comprehension of the video and was designed to test if children had payed attention to the video.  For the children it was a 4 question test.  Of the 91 children, 4 had a score of 2, 28 a score of 3, and 59 a score of 4.  And we have not filtered out any children from the data frame based on this comprehension check.  
\newpage
 (i) There is also a `SRTotal` variable for the adults.  We did not include it in the data frame.  If it is also a comprehension check, it might be useful consider filtering out some of the adults based on the results.  This is a table of the results:
``` {r echo=FALSE, message=FALSE, warning=FALSE}
k <- data.frame(score=as.character(seq(6, 12)), count=as.character(c(1,1,15,18,40,37,20)))
kable(t(k))
```
 
  (j) We have renamed the `Condition` levels to `Obj` (object), `Nat` (nature, animal, vitalist), `Per` (person, psychological), for ease of understanding and consistency while we were coding.  
  
  (k) For a better model fit, we have combined the original 13 levels of `MeanSeverity` into three levels, as follows:  
``` {r echo=FALSE, message=FALSE, warning=FALSE}
k <- data.frame(original=as.character(format(round(seq(0, 3, .25), 3))), combined=as.character(c(1,1,1,1,1,1,2,2,2,3,3,3,3)))
kable(t(k), align="c")
```
  
  (l) For a better model fit, we have combined the original 5 levels of `BioJtscore` (the number of scenarios where the respondent used a biocentric justification), into three levels, as follows:  
``` {r echo=FALSE, message=FALSE, warning=FALSE}
l <- data.frame(original=as.character(seq(0, 4)), combined=as.character(c(1,1,1,2,3)))
kable(t(l))  
```
  
  (m) For a better model fit, we have combined the original 5 levels of `AntJtscore` (the number of scenarios where the respondent used an anthropocentric justification), into three levels, as follows:  
``` {r echo=FALSE, message=FALSE, warning=FALSE}
m <- data.frame(original=as.character(seq(0, 4)), combined=as.character(c(1,1,1,2,3)))
kable(t(m))  
```
  
  (n) For a better model fit, we have combined the original 5 levels of `BioJFtotal` (the number of scenarios where the respondent chose biocentric when given a choice between biocentric and anthropocentric), into three levels, as follows:  
``` {r echo=FALSE, message=FALSE, warning=FALSE}
n <- data.frame(original=as.character(seq(0, 4)), combined=as.character(c(1,1,2,3,3)))
kable(t(n))  
```
  
```{r echo=FALSE}

setwd("~/MSSP/Consulting/EarthAgencyProject")
adult <- read.csv("EarthAgency_Adults_R.csv", header = TRUE)
children <- read.csv("EarthAgency_Children_R.csv", header = TRUE)

adult_df <- adult %>%
  dplyr::select(
    Condition,
    Agency_Language,
    SRFactsTotal,
    invitalscore,
    inpsychscore,
    MeanSever,
    BioJtscore,
    AntJtscore,
    BioJFtotal,
    FirstLang,
    Age
  ) %>%
  mutate(
    Condition = as.factor(Condition),
    SRFactsTotal = as.integer(SRFactsTotal),
    invitalscore = as.integer(invitalscore),
    inpsychscore = as.integer(inpsychscore),
    Agency_Language = as.factor(Agency_Language),
    FirstLang = as.factor(FirstLang),
    Age
  )

#compress scores to match invitalscore and inpsychscore for children

adult_df$invitalscore[which(adult_df$invitalscore==0 | adult_df$invitalscore==1)]<-0
adult_df$invitalscore[which(adult_df$invitalscore==2) ]<-1
adult_df$invitalscore[which(adult_df$invitalscore==3) ]<-2
adult_df$invitalscore[which(adult_df$invitalscore==4 | adult_df$invitalscore==5)]<-3

adult_df$inpsychscore[which(adult_df$inpsychscore==2 | adult_df$inpsychscore==3)]<-2
adult_df$inpsychscore[which(adult_df$inpsychscore==4)]<-3
adult_df$inpsychscore[which(adult_df$inpsychscore==5)]<-4

child_df <- children %>%
  dplyr::select(
    Condition,
    Agency_Language,
    SRFactsTotal,
    invitalscore,
    inpsychscore,
    MeanSever,
    BioJtscore,
    AntJtscore,
    BioJFtotal,
    Age
  ) %>%
  mutate(
    Condition = as.factor(Condition),
    SRFactsTotal = as.integer(SRFactsTotal),
    invitalscore = as.integer(invitalscore),
    inpsychscore = as.integer(inpsychscore),
    Agency_Language = as.factor(Agency_Language),
    Age 
  )

#We're not sure we have the coding for FirstLang correct (1 = speaking their first language??)
FirstLang <- rep(1, nrow(child_df))
child_df <- child_df %>% 
  mutate(
    FirstLang = as.factor(FirstLang),
    )

#To take care of the one errant entry, children[87] (mean severity scores are divided by 4 so .67 is not possibleâ€¦)
child_df$MeanSever[child_df$MeanSever==2.67] <- 2.5

#To remove children[41] which has no BIoJtscore or AntJtscore
#To remove children[45] which has no Agency_Language or SRFactsTotal
child_df <- na.omit(child_df)

## COMBINING children and adult into one data.frame
AC_df <- rbind(adult_df, child_df)

#Giving factor levels cleaner language
AC_df$Condition <- revalue(AC_df$Condition, c("1"="Obj", "2"="Nat", "3"="Per"))
AC_df$Agency_Language <- revalue(AC_df$Agency_Language, c("0"="Obj", "2"="Nat", "3"="Per"))
AC_df$Age <- ifelse(AC_df$Age > 10, "Adult", "Child")
AC_df$Age <- factor(AC_df$Age)
```
\newpage
## 2. Experimental Design concerns  
The chart below shows our understanding of the variables collected.  The green are the independent variables with their levels, and the brown are the four dependent variables.  As you have noted, the flow our your experiment design has intertwined the `Condition` variable with the `Agency_language`, `inpsychscore` and `invitalscore` variables.  In particular, since the questionnaire was given after the participants watched the video, it's not clear that the `invitalscore` and `inpsychscore` variables are measuring the participants underlying beliefs, or the beliefs expressed in the video that they just watched.  Also `Agency_language`, which is attempting to measure how the participants describe the video, overlaps with the perspective of the video watched.  As such it is not clear that `Agency_language` is descriptive of the participant or of the video they just watched.  

```{r, echo=FALSE, fig.align='center'}
include_graphics("List of Variables.pdf")
```
\newpage
## 3. Correlation among independent variables   
Because of our worry about the independence of the independent variables, we checked the correlations between the independent variables.  The following chart (which is redundant across the diagonal), shows Pearson product-moment correlations between the numeric variables (`SRFactsTotal`, `invitalscore`, `inpsychscore`), a polychoric correlations between ordinal categorical variables (`Condition`, `Agency_Language`, `FirstLang` and `Age`), and polyserial correlations between numeric and ordinal variables.  1 or -1 is a strong correlation.  0 is no correlation.   
\newline
```{r echo=FALSE, message=FALSE, warning=FALSE, comment=NA}
AC_indep <- AC_df %>%
  dplyr::select(
    Condition,
    Agency_Language,
    SRFactsTotal,
    invitalscore,
    inpsychscore,
    FirstLang,
    Age)

cor.check <- polycor::hetcor(AC_indep)
kable(round(cor.check$correlations,2))
```
  
## 3a. Correlation between `Condition` and `Agency_language`  
`Condition` and `Agency_language` had the strongest correlation and the p-value of the Pearson's chi-square test was effectively zero ($p=7.3*10^{-36}$).  Because of this, and because of our concerns about the experimental design, we have not included `Agency_language` in the model fits below.  But we are going to explore using PCA (principal component analysis) to combine these two independent variables.  
```{r echo=FALSE, warning=FALSE, out.width="33%"}
pvalue <- chisq.test(table(AC_df$Condition, AC_df$Agency_Language), simulate.p.value = FALSE)$p.value
balloonplot(table(AC_df$Condition, AC_df$Agency_Language), xlab ="Condition", ylab="Agency_Lang",
            label = TRUE, show.margins = TRUE, label.size=.5)

```
  
\newpage  
## 3b. Correlation between `Condition`, `invitalscore`, and `inpsychscore`  
A Chi-square test shows that there is not a significant correlation between `Condition` and `invitalscore` (p=0.54), and there is a slightly significant correlation between `Condition` and `inpsychscore` (p=0.04).  But the correlation between `invitalscore` and `inpsychscore` is highly significant ($p=5.0*10^{-4}$).  And we are going to explore using PCA (principal component analysis) to combine these two independent variables (`invitalscore` and `inpsychsocre`).  But in the models below we have included both.  

```{r echo=FALSE, warning=FALSE, out.width="33%"}
pvalue.1 <- chisq.test(table(AC_df$Condition, AC_df$invitalscore), simulate.p.value = FALSE)$p.value
balloonplot(table(AC_df$Condition, AC_df$invitalscore), xlab ="Condition", ylab="invitalscore",
            label = TRUE, show.margins = TRUE, label.size=.5)

pvalue.2 <- chisq.test(table(AC_df$Condition, AC_df$inpsychscore), simulate.p.value = FALSE)$p.value
balloonplot(table(AC_df$Condition, AC_df$inpsychscore), xlab ="Condition", ylab="inpsychscore",
            label = TRUE, show.margins = TRUE, label.size=.5)

pvalue.3 <- chisq.test(table(AC_df$inpsychscore, AC_df$invitalscore), simulate.p.value = TRUE)$p.value
balloonplot(table(AC_df$invitalscore, AC_df$inpsychscore), xlab ="invitalscore", ylab="inpsychscore",
            label = TRUE, show.margins = TRUE, label.size=.5)
```
  
## 3c. Correlation between `FirstLang` and `Age`  
Because we are assuming that the 89 children in the study are all using their first language, there is a strong correlation between `FirstLang` and `Age` ($p=2.4*10^{-6}$).  And for contectual reasons, we have left both of these variables in the models below.
```{r echo=FALSE, warning=FALSE, out.width="33%"}
pvalue.4 <- chisq.test(table(AC_df$FirstLang, AC_df$Age), simulate.p.value = FALSE)$p.value
balloonplot(table(AC_df$FirstLang, AC_df$Age), xlab ="First Language", ylab="Age",
            label = TRUE, show.margins = TRUE, label.size=.5)
```
```{r echo=FALSE}
## Are Condition and SRFactsTotal  correlated????  
## The ordinal regression shows more facts remembered the more likely "Per" and the less likely "Obj" (BUT it's not a really big difference in the probability of being in that particular group...).  BUT t-tests show there is no significant difference in mean SRFactsTotal between any of the combinations of "Obj", "Nat", or "Per"

##plot shows no visual correlation
#plot(AC_df$Condition, AC_df$SRFactsTotal)

##combination of t-tests shows no associatin
#t.test(AC_df$SRFactsTotal[AC_df$Condition=="Obj"], AC_df$SRFactsTotal[AC_df$Condition=="Nat"], alternative = "two.sided", var.equal = FALSE)
#t.test(AC_df$SRFactsTotal[AC_df$Condition=="Obj"], AC_df$SRFactsTotal[AC_df$Condition=="Per"], alternative = "two.sided", var.equal = FALSE)
#t.test(AC_df$SRFactsTotal[AC_df$Condition=="Per"], AC_df$SRFactsTotal[AC_df$Condition=="Nat"], alternative = "two.sided", var.equal = FALSE)

##ordinal regression shows no predictive value for SRFactsTotal - the probability for all three conditions ranges from 32% to 34% (even though there are different patterns to the probobilities within this small range)
#Condition_ordinal <- polr(Condition ~ SRFactsTotal, AC_df)
#summary(Condition_ordinal)

#plot(facts, predict(Condition_ordinal, newdata=data.frame(SRFactsTotal=facts), type="p")[,1], type='l', ylab='Prob', ylim=c(.32,.34))
  #lines(facts, predict(Condition_ordinal, newdata=data.frame(SRFactsTotal=facts), type="p")[,2], col='red')
  #lines(facts, predict(Condition_ordinal, newdata=data.frame(SRFactsTotal=facts), type="p")[,3], col='blue')
  #legend("topleft", lty=1, col=c("black", "red", "blue"), legend=c("Object", "Nature", "Person"))

##This code does the same as above - but using the logit formula - it has not been graphed, but would be graphed the same as the plot above
facts   <- seq(from=0, to=15, by=1)
xbeta <- facts*(0.003059)
logistic_cdf <- function(x) {
  return( 1/(1+exp(-x) ) )
}

p1 <- logistic_cdf( -0.6983 - xbeta )
p2 <- logistic_cdf( 0.7084 - xbeta ) - logistic_cdf( -0.6983 - xbeta )
p3 <- 1 - logistic_cdf( 0.7084 - xbeta )

```
\newpage
## 4a. Linear models
We need to interpret the linear models and the binnedplots.  And give a rationale for why we aren't using these models.
```{r echo=FALSE, comment=NA}
lm.fit1 <- lm(MeanSever ~ Condition + 
                SRFactsTotal + invitalscore + inpsychscore + FirstLang + Age, data = AC_df)
summary(lm.fit1)

lm.fit2 <- lm(BioJtscore ~ Condition +  
                SRFactsTotal + invitalscore + inpsychscore + FirstLang + Age, data = AC_df)

summary(lm.fit2)

lm.fit3 <- lm(AntJtscore ~ Condition + 
                SRFactsTotal + invitalscore + inpsychscore + FirstLang + Age, data = AC_df)

summary(lm.fit3)

lm.fit4 <- lm(BioJFtotal ~ Condition + 
                SRFactsTotal + invitalscore + inpsychscore + FirstLang + Age, data = AC_df)

summary(lm.fit4)


```
## 4b. Binned residual plots
```{r echo=FALSE, comment=NA}
par(mfrow=c(2,2))
binnedplot(fitted(lm.fit1),resid(lm.fit1), main="MeanSeverity")
binnedplot(fitted(lm.fit2),resid(lm.fit2), main="BioJustification score")
binnedplot(fitted(lm.fit3),resid(lm.fit3), main="AnthroJustification score")
binnedplot(fitted(lm.fit4),resid(lm.fit4), main="BioOrAnthro choice")
```
## 4c. ANOVA for linear model of Mean Severity
```{r echo=FALSE, comment=NA}

lm.fit1b <- lm(MeanSever ~ Condition + 
                SRFactsTotal + invitalscore + inpsychscore + FirstLang, data = AC_df)
anova(lm.fit1, lm.fit1b)

```

# 5a. Mean Severity Ordinal model with combined levels
Do we want to do an F1 test aside from misclassification error to evaluate the model??
```{r echo=FALSE, message=FALSE, comment=NA}
#Meansever combined into three levels (bcm)
AC_df$comMeanSever <- AC_df$MeanSever
AC_df$comMeanSever[which((AC_df$MeanSever < 1.5))]<-1
AC_df$comMeanSever[which((AC_df$MeanSever > 1.25 & AC_df$MeanSever < 2.25))]<-2
AC_df$comMeanSever[which((AC_df$MeanSever > 2))]<-3
AC_df$comMeanSever <- factor(AC_df$comMeanSever, ordered = TRUE)

cat("original levels")
table(AC_df$MeanSever)
cat("combined levels")
table(AC_df$comMeanSever)

plor.fit1c <- polr(comMeanSever ~  Condition + SRFactsTotal + invitalscore  + inpsychscore + FirstLang + Age, data = AC_df)
#summary(plor.fit1c)

#Get p-value
ctable <- round(coef(summary(plor.fit1c)), 3)
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
ctable1 <- cbind(ctable, "p value" =round(p, 3))
ctable1

#Compute confusion table and misclassification error
fitted <- predict(plor.fit1c)
n <- table(AC_df$comMeanSever, fitted)
prop.correct <- c(n[1,1]/sum(n[1,]),n[2,2]/sum(n[2,]),n[3,3]/sum(n[3,]))
prop.correct <- round(100*prop.correct, 0)
rbind(n,prop.correct)
ME <- mean(as.character(AC_df$comMeanSever) !=as.character(fitted))
cat("Misclassification error is:",ME,"\n")
```

# 5b. Biocentric Justification score, Ordinal model with combined levels
```{r echo=FALSE, message=FALSE, comment=NA}
#BioJtscore with Combination (bcm)
AC_df$comBioJtscore<-AC_df$BioJtscore
AC_df$comBioJtscore[which((AC_df$comBioJtscore==0))]<-1
AC_df$comBioJtscore[which((AC_df$comBioJtscore==2))]<-1
AC_df$comBioJtscore[which((AC_df$comBioJtscore==3))]<-2
AC_df$comBioJtscore[which((AC_df$comBioJtscore==4))]<-3
AC_df$comBioJtscore<- factor(AC_df$comBioJtscore, ordered = TRUE)

cat("original levels")
table(AC_df$BioJtscore)
cat("combined levels")
table(AC_df$comBioJtscore)

plor.fit2c <- polr(comBioJtscore ~  Condition + SRFactsTotal +invitalscore  + inpsychscore + FirstLang+Age, data = AC_df)
#summary(plor.fit2c)

#Get p-value
ctable <- round(coef(summary(plor.fit2c)), 3)
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
ctable1 <- cbind(ctable, "p value" = round(p, 3))
ctable1

#Compute confusion table and misclassification error
fitted <- predict(plor.fit2c)
n <- table(AC_df$comBioJtscore, fitted)
prop.correct <- c(n[1,1]/sum(n[1,]),n[2,2]/sum(n[2,]),n[3,3]/sum(n[3,]))
prop.correct <- round(100*prop.correct, 0)
rbind(n,prop.correct)
ME <- mean(as.character(AC_df$comBioJtscore) !=as.character(fitted))
cat("Misclassification error is:",ME,"\n")
```

# 5c. Anthropocentric Justification score, Ordinal model with combined levels
```{r echo=FALSE, message=FALSE, comment=NA}
#AntJtscore with Combination (bcm)
AC_df$comAntJtscore<-AC_df$AntJtscore
AC_df$comAntJtscore[which((AC_df$comAntJtscore==0))]<-1
AC_df$comAntJtscore[which((AC_df$comAntJtscore==2))]<-1
AC_df$comAntJtscore[which((AC_df$comAntJtscore==3))]<-2
AC_df$comAntJtscore[which((AC_df$comAntJtscore==4))]<-3
AC_df$comAntJtscore<- factor(AC_df$comAntJtscore, ordered = TRUE)

cat("original levels")
table(AC_df$AntJtscore)
cat("combined levels")
table(AC_df$comAntJtscore)

plor.fit3c<- polr(comAntJtscore~  Condition + SRFactsTotal +invitalscore  + inpsychscore + FirstLang+Age, data = AC_df)
#summary(plor.fit3c)

#Get p-value
ctable <- round(coef(summary(plor.fit3c)), 3)
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
ctable1 <- cbind(ctable, "p value" = round(p, 3))
ctable1

#Compute confusion table and misclassification error
fitted <- predict(plor.fit3c)
n <- table(AC_df$comAntJtscore, fitted)
prop.correct <- c(n[1,1]/sum(n[1,]),n[2,2]/sum(n[2,]),n[3,3]/sum(n[3,]))
prop.correct <- round(100*prop.correct, 0)
rbind(n,prop.correct)
ME <- mean(as.character(AC_df$comAntJtscore) !=as.character(fitted))
cat("Misclassification error is:",ME,"\n")
```

# 5d. Biocentric choice score, Ordinal model with combined levels
```{r echo=FALSE, message=FALSE, comment=NA}
#BioJFtotal with Combination
AC_df$comBioJFtotal<-AC_df$BioJFtotal
AC_df$comBioJFtotal[which((AC_df$comBioJFtotal==0))]<-1
#AC_df$comBioJFtotal[which((AC_df$comBioJFtotal==2))]<-1
#AC_df$comBioJFtotal[which((AC_df$comBioJFtotal==3))]<-2
AC_df$comBioJFtotal[which((AC_df$comBioJFtotal==4))]<-3
AC_df$comBioJFtotal<- factor(AC_df$comBioJFtotal, ordered = TRUE)

cat("original levels")
table(AC_df$BioJFtotal)
cat("combined levels")
table(AC_df$comBioJFtotal)

plor.fit4c <- polr(comBioJFtotal ~  Condition + SRFactsTotal +invitalscore  + inpsychscore + FirstLang+Age, data = AC_df)
#summary(plor.fit4c)

#Get p-value
ctable <- round(coef(summary(plor.fit4c)), 3)
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
ctable1 <- cbind(ctable, "p value" = round(p, 3))
ctable1

#Compute confusion table and misclassification error
fitted <- predict(plor.fit4c)
n <- table(AC_df$comBioJFtotal, fitted)
prop.correct <- c(n[1,1]/sum(n[1,]),n[2,2]/sum(n[2,]),n[3,3]/sum(n[3,]))
prop.correct <- round(100*prop.correct, 0)
rbind(n,prop.correct)
ME <- mean(as.character(AC_df$comBioJFtotal) !=as.character(fitted))
cat("Misclassification error is:",ME,"\n")
```
  
## 6. ANOVA for ordinal models
This is code that Maggie added to check the ANOVA for the polr() models.  Not sure if this is correct (Zihuan said that we needed to check how you do ANOVA for ordinal models).  And this is just checking the Age variable.  Not the Condition variable.
```{r echo=FALSE, comment=NA}
#Mean Severity
plor.fit1c2 <- polr(comMeanSever ~  Condition +  SRFactsTotal + invitalscore  + inpsychscore + FirstLang, data = AC_df)

anova(plor.fit1c, plor.fit1c2)


#Biocentric Justification score
plor.fit2c2 <- polr(comBioJtscore ~  Condition +  SRFactsTotal +invitalscore  + inpsychscore + FirstLang, data = AC_df)

anova(plor.fit2c, plor.fit2c2)


#Anthropocentric Justification score
plor.fit3c2<- polr(comAntJtscore~  Condition +  SRFactsTotal +invitalscore  + inpsychscore + FirstLang, data = AC_df)

anova(plor.fit3c,plor.fit3c2)


#Biocentric choice score
plor.fit4c2 <- polr(comBioJFtotal ~  Condition +  SRFactsTotal +invitalscore  + inpsychscore + FirstLang, data = AC_df)

anova(plor.fit4c,plor.fit4c2)
```